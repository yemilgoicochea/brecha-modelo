{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNgPvDT3RlBWUbdBWevgSz6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cSeFLa-h-ptU","executionInfo":{"status":"ok","timestamp":1765382366680,"user_tz":300,"elapsed":109,"user":{"displayName":"Natalia Carrasco","userId":"01462194267021436977"}},"outputId":"28c95c28-e43b-452d-9994-7975fb94d539"},"outputs":[{"output_type":"stream","name":"stdout","text":["===== RESUMEN ===telek\n","Filas evaluadas realmente: 593\n","Accuracy multilabel: 0.4671\n","Accuracy multiclass: 0.6610\n","Reporte generado en 'reporte_evaluacion.txt'\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/preprocessing/_label.py:909: UserWarning: unknown class(es) [0] will be ignored\n","  warnings.warn(\n","/tmp/ipython-input-652288083.py:160: RuntimeWarning: invalid value encountered in divide\n","  cm_norm = np.nan_to_num(cm.astype(float) / cm.sum(axis=1, keepdims=True))\n"]}],"source":["import json\n","import pandas as pd\n","import numpy as np\n","\n","from sklearn.metrics import (\n","    accuracy_score,\n","    precision_recall_fscore_support,\n","    confusion_matrix,\n","    multilabel_confusion_matrix\n",")\n","from sklearn.preprocessing import MultiLabelBinarizer\n","\n","\n","# ================================================================\n","# Funciones auxiliares\n","# ================================================================\n","\n","def safe_parse_json(json_str):\n","    \"\"\"Parsea JSON de forma segura.\"\"\"\n","    if pd.isna(json_str):\n","        return None\n","    if isinstance(json_str, dict):\n","        return json_str\n","    if not isinstance(json_str, str):\n","        return None\n","    try:\n","        return json.loads(json_str)\n","    except json.JSONDecodeError:\n","        return None\n","\n","\n","def extract_ids(json_obj):\n","    \"\"\"\n","    Extrae IDs predichos desde JSON_RPTA.\n","    Si no encuentra ningún 'id', retorna set vacío y main_id=None.\n","    \"\"\"\n","    if not isinstance(json_obj, dict):\n","        return set(), None\n","\n","    labels = json_obj.get(\"labels\", [])\n","    if not isinstance(labels, list):\n","        return set(), None\n","\n","    ids = set()\n","    main_id = None\n","    max_conf = -1\n","\n","    for item in labels:\n","        if not isinstance(item, dict):\n","            continue\n","\n","        pred_id = item.get(\"id\")\n","        if pred_id is None:\n","            continue  # No se considera la fila si no tiene ids\n","\n","        try:\n","            pred_id = int(pred_id)\n","        except:\n","            continue\n","\n","        ids.add(pred_id)\n","\n","        conf = item.get(\"confianza\", 0)\n","        try:\n","            conf = float(conf)\n","        except:\n","            conf = 0\n","\n","        if conf > max_conf:\n","            max_conf = conf\n","            main_id = pred_id\n","\n","    return ids, main_id\n","\n","\n","# ================================================================\n","# LECTURA DEL CSV\n","# ================================================================\n","df = pd.read_csv(\"resultados1.csv\", encoding=\"utf-8\", sep=\";\")\n","\n","# Quitar filas con ID real == 0\n","df = df[df[\"ID\"] != 0].copy()\n","\n","# ================================================================\n","# EVALUACIÓN\n","# ================================================================\n","y_true_multi = []\n","y_pred_multi = []\n","\n","y_true_mc = []\n","y_pred_mc = []\n","\n","filas_descartadas_json = 0\n","\n","for idx, row in df.iterrows():\n","\n","    true_id = int(row[\"ID\"])\n","    json_obj = safe_parse_json(row.get(\"JSON_RPTA\"))\n","\n","    if json_obj is None:\n","        filas_descartadas_json += 1\n","        continue\n","\n","    pred_ids, main_id = extract_ids(json_obj)\n","\n","    # Regla nueva: si NO trae ids → no usar para comparar\n","    if len(pred_ids) == 0:\n","        filas_descartadas_json += 1\n","        continue\n","\n","    # MULTILABEL\n","    y_true_multi.append({true_id})\n","    y_pred_multi.append(pred_ids)\n","\n","    # MULTICLASS\n","    y_true_mc.append(true_id)\n","    y_pred_mc.append(main_id if main_id is not None else 0)\n","\n","# Si no quedan filas válidas, abortar\n","n_validas = len(y_true_multi)\n","if n_validas == 0:\n","    print(\"No hay filas válidas para evaluación.\")\n","    exit()\n","\n","# ================================================================\n","# MÉTRICAS MULTILABEL\n","# ================================================================\n","ids_reales = sorted({list(x)[0] for x in y_true_multi})  # ground truth único por fila\n","mlb = MultiLabelBinarizer(classes=ids_reales)\n","\n","Y_true_ml = mlb.fit_transform(y_true_multi)\n","Y_pred_ml = mlb.transform(y_pred_multi)\n","\n","accuracy_ml = accuracy_score(Y_true_ml, Y_pred_ml)\n","\n","prec_micro, rec_micro, f1_micro, _ = precision_recall_fscore_support(\n","    Y_true_ml, Y_pred_ml, average=\"micro\", zero_division=0\n",")\n","prec_macro, rec_macro, f1_macro, _ = precision_recall_fscore_support(\n","    Y_true_ml, Y_pred_ml, average=\"macro\", zero_division=0\n",")\n","prec_weighted, rec_weighted, f1_weighted, _ = precision_recall_fscore_support(\n","    Y_true_ml, Y_pred_ml, average=\"weighted\", zero_division=0\n",")\n","\n","prec_cat, rec_cat, f1_cat, support_cat = precision_recall_fscore_support(\n","    Y_true_ml, Y_pred_ml, average=None, zero_division=0\n",")\n","\n","ml_conf_matrices = multilabel_confusion_matrix(Y_true_ml, Y_pred_ml)\n","\n","\n","# ================================================================\n","# MÉTRICAS MULTICLASS\n","# ================================================================\n","acc_mc = accuracy_score(y_true_mc, y_pred_mc)\n","\n","ids_presentes = sorted(set(y_true_mc) | set(y_pred_mc))\n","cm = confusion_matrix(y_true_mc, y_pred_mc, labels=ids_presentes)\n","cm_norm = np.nan_to_num(cm.astype(float) / cm.sum(axis=1, keepdims=True))\n","\n","\n","# ================================================================\n","# GENERAR REPORTE\n","# ================================================================\n","lines = []\n","\n","lines.append(\"REPORTE DE EVALUACIÓN DEL CLASIFICADOR\\n\")\n","lines.append(\"======================================\\n\\n\")\n","lines.append(f\"Filas originales con ID != 0: {len(df)}\\n\")\n","lines.append(f\"Filas **usadas** realmente en métricas: {n_validas}\\n\")\n","lines.append(f\"Filas descartadas (JSON sin id o no válido): {filas_descartadas_json}\\n\\n\")\n","\n","lines.append(\"1. Métricas Globales (Multilabel)\\n\")\n","lines.append(\"---------------------------------\\n\")\n","lines.append(f\"Accuracy multilabel: {accuracy_ml:.4f}\\n\\n\")\n","lines.append(f\"Micro Precision: {prec_micro:.4f}\\n\")\n","lines.append(f\"Micro Recall: {rec_micro:.4f}\\n\")\n","lines.append(f\"Micro F1: {f1_micro:.4f}\\n\\n\")\n","lines.append(f\"Macro Precision: {prec_macro:.4f}\\n\")\n","lines.append(f\"Macro Recall: {rec_macro:.4f}\\n\")\n","lines.append(f\"Macro F1: {f1_macro:.4f}\\n\\n\")\n","lines.append(f\"Weighted Precision: {prec_weighted:.4f}\\n\")\n","lines.append(f\"Weighted Recall: {rec_weighted:.4f}\\n\")\n","lines.append(f\"Weighted F1: {f1_weighted:.4f}\\n\\n\")\n","\n","lines.append(\"2. Métricas por Categoría (One-vs-Rest)\\n\")\n","lines.append(\"--------------------------------------\\n\")\n","lines.append(\"ID\\tPrecision\\tRecall\\tF1\\tSupport\\n\")\n","for i, cid in enumerate(mlb.classes_):\n","    lines.append(\n","        f\"{cid}\\t{prec_cat[i]:.4f}\\t{rec_cat[i]:.4f}\\t{f1_cat[i]:.4f}\\t{support_cat[i]}\\n\"\n","    )\n","\n","lines.append(\"\\n3. Matriz de Confusión Multilabel (One-vs-Rest)\\n\")\n","for i, cid in enumerate(mlb.classes_):\n","    tn, fp, fn, tp = ml_conf_matrices[i].ravel()\n","    lines.append(f\"\\nID {cid}: [[TN={tn}, FP={fp}], [FN={fn}, TP={tp}]]\\n\")\n","\n","lines.append(\"\\n4. Métricas Globales (Multiclass)\\n\")\n","lines.append(\"--------------------------------\\n\")\n","lines.append(f\"Accuracy multiclass: {acc_mc:.4f}\\n\")\n","lines.append(\"Nota: predicción 0 = sin predicción.\\n\\n\")\n","\n","lines.append(\"5. Matriz de Confusión Multiclase (Valores absolutos)\\n\")\n","header = \"ID_real\\\\ID_pred\\t\" + \"\\t\".join(str(c) for c in ids_presentes) + \"\\n\"\n","lines.append(header)\n","for i, real_id in enumerate(ids_presentes):\n","    row_vals = \"\\t\".join(str(v) for v in cm[i])\n","    lines.append(f\"{real_id}\\t\\t{row_vals}\\n\")\n","\n","lines.append(\"\\n6. Matriz de Confusión Multiclase Normalizada (%)\\n\")\n","lines.append(header)\n","for i, real_id in enumerate(ids_presentes):\n","    row_vals = \"\\t\".join(f\"{v*100:.2f}\" for v in cm_norm[i])\n","    lines.append(f\"{real_id}\\t\\t{row_vals}\\n\")\n","\n","# Guardar archivo\n","with open(\"reporte_evaluacion.txt\", \"w\", encoding=\"utf-8\") as f:\n","    for line in lines:\n","        f.write(line if line.endswith(\"\\n\") else line + \"\\n\")\n","\n","# Resumen en consola\n","print(\"===== RESUMEN ===telek\")\n","print(f\"Filas evaluadas realmente: {n_validas}\")\n","print(f\"Accuracy multilabel: {accuracy_ml:.4f}\")\n","print(f\"Accuracy multiclass: {acc_mc:.4f}\")\n","print(\"Reporte generado en 'reporte_evaluacion.txt'\")"]}]}